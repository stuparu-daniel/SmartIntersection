# ğŸš¦ Traffic Light Optimization using Deep Reinforcement Learning

## ğŸ“Œ Overview
This project optimizes traffic light phases using **Deep Reinforcement Learning (DQN)** to minimize **waiting time** at red lights and **maximize vehicle speeds**. The system dynamically adjusts **green and yellow phase durations** in real-time using **SUMO (Simulation of Urban Mobility)**.

## ğŸ—ï¸ Architecture
### **1ï¸âƒ£ Environment (`env.py`)**
- Uses **SUMO** to simulate traffic.
- Defines **state representation** (number of vehicles, speeds, current phase, etc.).
- Implements **step function** to interact with SUMO and update the environment.
- Computes **reward function** based on **waiting time reduction** and **speed optimization**.

### **2ï¸âƒ£ Reinforcement Learning Agent (`dqn.py`)**
The RL model is a **Deep Q-Network (DQN)** with the following architecture (may and sholud be modified as development proceeds):
```plaintext
Input Layer  â  Fully Connected (Hidden Layer 1, X neurons)  â  ReLU Activation
             â  Fully Connected (Hidden Layer 2, X neurons)  â  ReLU Activation
             â  Fully Connected (Output Layer, 5 Actions)   â  Q-Value Predictions
```
- **Input:** Traffic state (number of cars + average speeds per lane + phase info).
- **Output:** Action (adjust green/yellow phase duration or keep it unchanged).
- **Loss Function:** Mean Squared Error (MSE)
- **Optimizer:** Adam

### **3ï¸âƒ£ Training Loop (`train.py`)**
- Iterates over **different hidden layer sizes** (`64, 128, 256, 512, 1024`) (not definitive as of right now).
- Dynamically **modifies traffic flow (`flow_modifier.py`)** before each episode.
- Saves the best-performing model for each configuration.
- Logs total waiting time and average speed for visualization.

## ğŸ“Š Visualization
- **Graphs training results** using `visualize.py`.
- Plots total waiting time for different network configurations.
- Each modelâ€™s performance is compared in a single graph.

## ğŸš€ How to Run
1. Install SUMO and dependencies.
2. Run the training script:
   ```sh
   python train.py
   ```
3. Visualize results:
   ```sh
   python visualize.py
   ```

## ğŸ“ Project Structure
```plaintext
ğŸ“‚ project_root/
 â”œâ”€â”€ ğŸ“œ README.md              # This file
 â”œâ”€â”€ ğŸ“ train.py               # Training loop for RL agent
 â”œâ”€â”€ ğŸ¤– dqn.py                 # Deep Q-Network model
 â”œâ”€â”€ ğŸš¦ env.py                 # SUMO Traffic Simulation Environment
 â”œâ”€â”€ ğŸ“Š visualize.py           # Graphs training results
 â”œâ”€â”€ ğŸ› ï¸ util.py                 # Helper functions
 â”œâ”€â”€ ğŸ™ï¸ flow_modifier.py        # Modifies vehicle density per episode
 â”œâ”€â”€ ğŸ“œ constants.py           # Stores global constants
 â”œâ”€â”€ ğŸ“‚ sumo_simulation/       # SUMO network files
 â”‚   â”œâ”€â”€  Test3.sumocfg      # SUMO simulation configuration
 â”‚   â”œâ”€â”€  Test3.net.xml      # Road network file
 â”‚   â”œâ”€â”€  Test3.rou.xml      # Vehicle routes (dynamically modified)
 â”œâ”€â”€ ğŸ“‚ models/                # Saved RL models
 â”œâ”€â”€ ğŸ“‚ logs/                  # Training logs
```

## âš™ï¸ Dependencies
- **Python 3.10+**
- **SUMO** (Simulation of Urban Mobility)
- `traci` (SUMO Python API)
- `numpy`
- `torch`
- `matplotlib`
